{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "utility-nancy",
   "metadata": {},
   "source": [
    "# Recommender System based on Regularized Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vulnerable-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, Predictor, als, basic, user_knn\n",
    "from lenskit import topn\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lenskit.data import sparse_ratings\n",
    "\n",
    "# Dataset\n",
    "from lenskit.datasets import ML100K\n",
    "movielens = ML100K('../ml-100k')\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Visualizations and debugging\n",
    "import plotly.graph_objs as go\n",
    "#from pprintpp import pprint as pp\n",
    "import logging\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hungry-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.datasets import ML100K\n",
    "movielens = ML100K('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "current-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "ratings = movielens.ratings\n",
    "uir, users, items = sparse_ratings(ratings, scipy=True)\n",
    "M = uir\n",
    "lambda1,lambda2,tol = 1.0,10.0,1e-3\n",
    "X_o=csr_matrix(M.shape)\n",
    "Z=csr_matrix(M.shape)\n",
    "Gamma=csr_matrix(M.shape)\n",
    "M_s = (uir!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "public-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds, eigs, norm\n",
    "from scipy.sparse import csr_matrix\n",
    "from numpy import linalg as LA\n",
    "from numba import jit, njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sixth-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@njit(parallel=True)\n",
    "@jit(nopython=True)\n",
    "def matrix_factorization_pred(X,P,Q,K,steps,alpha,beta,Mask):\n",
    "#    Mask = (X!=0)\n",
    "    Q = Q.T\n",
    "    error_list = np.zeros(steps)\n",
    "    for step in range(steps):\n",
    "        print(step)\n",
    "        #for each user\n",
    "        for i in prange(X.shape[0]):\n",
    "            #for each item\n",
    "            for j in range(X.shape[1]):\n",
    "                if X[i,j] > 0 :\n",
    "\n",
    "                    #calculate the error of the element\n",
    "                    eij = X[i,j] - np.dot(P[i,:],Q[:,j])\n",
    "                    #second norm of P and Q for regularilization\n",
    "                    sum_of_norms = 0\n",
    "                    #for k in xrange(K):\n",
    "                    #    sum_of_norms += LA.norm(P[:,k]) + LA.norm(Q[k,:])\n",
    "                    #added regularized term to the error\n",
    "                    sum_of_norms += LA.norm(P) + LA.norm(Q)\n",
    "                    #print sum_of_norms\n",
    "                    eij += ((beta/2) * sum_of_norms)\n",
    "                    #compute the gradient from the error\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * ( 2 * eij * Q[k][j] - (beta * P[i][k]))\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - (beta * Q[k][j]))\n",
    "\n",
    "        #compute total error\n",
    "        error = 0\n",
    "        #for each user\n",
    "        extimated_X = np.trunc(P @ Q)\n",
    "        extimated_X = np.where(extimated_X>5, 5, extimated_X)\n",
    "        extimated_X = np.where(extimated_X<0, 0, extimated_X)\n",
    "        extimated_error = np.multiply(X - extimated_X, Mask)\n",
    "        error = LA.norm(extimated_error)\n",
    "        error_list[step] = error\n",
    "        \n",
    "        if error < 0.001:\n",
    "            break\n",
    "    return extimated_X, P, Q.T, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "overall-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(Recommender, Predictor):\n",
    "    \"\"\"\n",
    "    Recommend new items by completing the user-item rating matrix with regularized nonnegative matrix factorization\n",
    "    \"\"\"\n",
    "    def __init__(self, K=8, steps=300, alpha=0.0002, beta=float(0.02), selector = None):\n",
    "        \n",
    "        # Set selector\n",
    "        if selector is None:\n",
    "            self.selector = basic.UnratedItemCandidateSelector()\n",
    "        else:\n",
    "            self.selector = selector\n",
    "            \n",
    "        # Set parameters\n",
    "        self.steps = steps\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        # Enable logging \n",
    "        _logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'MatrixFactorization'\n",
    "            \n",
    "    # Store the ratings matrix in sparse format and generate similarity matrix\n",
    "    def fit(self, ratings, **kwargs):\n",
    "        \n",
    "        # Get sparse representation in CSR format\n",
    "        uir, users, items = sparse_ratings(ratings, scipy=True)\n",
    "        \n",
    "        # Store ratings\n",
    "        self.rating_matrix_ = uir\n",
    "        self.user_index_ = users\n",
    "        self.item_index_ = items\n",
    "        # Calculate mask matrix from rating matrix\n",
    "        self.mask_matrix = (self.rating_matrix_!=0)\n",
    "            \n",
    "        # Calculate similarites from sparse matrix\n",
    "######        self.sim_matrix_ = cosine_similarity(self.rating_matrix_)\n",
    "        \n",
    "        # Calculate completed u-i matrix matrix with matrix factorization\n",
    "                #Grab the input rating matrix and mask matrix\n",
    "        M = self.rating_matrix_\n",
    "        M_s = self.mask_matrix\n",
    "        #P: an initial matrix of dimension N x K, where is n is no of users and k is hidden latent features\n",
    "        P = np.random.rand(M.shape[0],self.K)\n",
    "        #Q : an initial matrix of dimension M x K, where M is no of movies and K is hidden latent features\n",
    "        Q = np.random.rand(M.shape[1],self.K)\n",
    "        \n",
    "        self.full_matrix_,_,_,_ = matrix_factorization_pred(M.todense(), P, Q, self.K, self.steps, self.alpha, self.beta, M_s.todense())               \n",
    "        \n",
    "        # Reduce candidate space to unseen items\n",
    "        self.selector.fit(ratings)\n",
    "\n",
    "            # Add a user to the ratings matrix\n",
    "    def add_user(self, user_id):\n",
    "        \n",
    "        # Check if user_id to be added already exists\n",
    "        try:\n",
    "            assert (user_id in self.user_index_) == False, \"User ID already exists! Not adding anything...\"\n",
    "        \n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "            exit(1)\n",
    "\n",
    "        # Build a sparse matrix of length of number of items\n",
    "        tmp_sparse_row = sparse.csr_matrix(np.zeros((1,len(self.item_index_))))\n",
    "\n",
    "        # Vertically stack temporary matrix to original matrix\n",
    "        self.rating_matrix_ = sparse.vstack([self.rating_matrix_, tmp_sparse_row])\n",
    "        \n",
    "        # Update user index\n",
    "        self.user_index_ = self.user_index_.append(pd.Index([user_id]))\n",
    "    \n",
    "        \n",
    "    # Add a user to the ratings matrix\n",
    "    def add_item(self, item_id):\n",
    "        \n",
    "        # Check if item_id to be added already exists\n",
    "        try:\n",
    "            assert (item_id in self.item_index_) == False, \"Item ID already exists!\"\n",
    "        \n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "            exit(1)\n",
    "        \n",
    "        # Build a sparse matrix of length of number of users\n",
    "        tmp_sparse_col = sparse.csr_matrix(np.zeros((len(self.user_index_),1)))\n",
    "        \n",
    "        # Horizotnally stack temporary matrix to original matrix\n",
    "        self.rating_matrix_ = sparse.hstack([self.rating_matrix_, tmp_sparse_col])\n",
    "        \n",
    "        # Update item index\n",
    "        self.item_index_ = self.item_index_.append(pd.Index([item_id]))\n",
    "        \n",
    "        \n",
    "    # Add a user-item interaction for existing users and items\n",
    "    def add_interactions(self, user_id, item_id, rating):\n",
    "    \n",
    "        # Check if inputs are lists and all input list lengths are equal\n",
    "        assert type(user_id) == list, \"Input user_id is not a list\"\n",
    "        assert type(item_id) == list , \"Input item_id is not a list\"\n",
    "        assert type(rating) == list, \"Input rating is not a list\"\n",
    "        assert len(user_id) == len(item_id) == len(rating), \"Input lists are not of the same length\"\n",
    "        \n",
    "        # Build a temporary sparse LIL matrix\n",
    "        \n",
    "        tmp_ratings = sparse.lil_matrix(self.rating_matrix_.shape)\n",
    "        \n",
    "        for i in range(len(user_id)):\n",
    "            \n",
    "            # Obtain locations from ID\n",
    "            user_pos, = np.where(self.user_index_ == user_id[i])[0]\n",
    "            item_pos, = np.where(self.item_index_ == item_id[i])[0]\n",
    "            \n",
    "            # Fill into temporary sparse matrix\n",
    "            tmp_ratings[user_pos, item_pos] = rating[i]\n",
    "                    \n",
    "        # Convert temporary LIL to CSR\n",
    "        tmp_ratings = tmp_ratings.tocsr()\n",
    "        \n",
    "        # Add temporary CSR to main ratings matrix\n",
    "        self.rating_matrix_ += tmp_ratings\n",
    "\n",
    "    # Provide a recommendation of top \"n\" movies given \"user\"\n",
    "    # The recommender uses the UnratedItemCandidateSelector by default and uses the ratings matrix \n",
    "    # it was originally fit on\n",
    "    def recommend(self, user_id, candidates=None, ratings=None):\n",
    "        \n",
    "        # Reduce candidate space and store candidates with item ID\n",
    "        if candidates is None:\n",
    "            candidates = self.selector.candidates(user_id, ratings)\n",
    "        \n",
    "        # Grab user index for given user_id\n",
    "        user_index, = np.where(self.user_index_ == user_id)[0]\n",
    "                \n",
    "        # Predict ratings and scores for all unseen items\n",
    "        prediction_score_df = self.predict_for_user(user_index, self.full_matrix_, candidates)\n",
    "        \n",
    "        return(prediction_score_df)\n",
    "    \n",
    "    \n",
    "    def predict_for_user(self, user, extimated_X, items):\n",
    "        \n",
    "        # Instantiate ratings and item_popularity vectors\n",
    "        predicted_ratings = np.zeros(len(items), dtype=float)\n",
    "        item_popularity = np.zeros(len(items), dtype=float)\n",
    "        \n",
    "        # Convert ratings matrix to COO matrix\n",
    "        coo_ratings = self.rating_matrix_.tocoo()\n",
    "        rating_matrix_users = coo_ratings.row\n",
    "        rating_matrix_items = coo_ratings.col\n",
    "        rating_matrix_data = coo_ratings.data                \n",
    "            \n",
    "        # For each unseen item\n",
    "        for i in range(len(items)):\n",
    "                        \n",
    "            # Item position given item i ID\n",
    "            item_pos = self.item_index_.get_loc(items[i])\n",
    "            \n",
    "            # Locations of ratings for item_pos\n",
    "            rating_locations, = np.where(rating_matrix_items == item_pos)\n",
    "            \n",
    "            # Store popularity of item based on number of total ratings \n",
    "            item_popularity[i] = len(rating_locations)\n",
    "            \n",
    "            #predicted_ratings[i] = extimated_X[user_pos,item_pos]\n",
    "            predicted_ratings[i] = extimated_X[user,item_pos]\n",
    "            \n",
    "        # minmax scale the popularity of each item\n",
    "        normalized_popularity = np.interp(item_popularity, (item_popularity.min(), item_popularity.max()), (0, +1))\n",
    "        score = np.multiply(normalized_popularity, predicted_ratings)\n",
    "        \n",
    "        results = {'predicted_ratings':predicted_ratings, 'normalized_popularity':normalized_popularity}\n",
    "        return pd.DataFrame(results, index=items)\n",
    "            \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "referenced-thinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "CPU times: user 4min 39s, sys: 11.8 s, total: 4min 51s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Instantiate object\n",
    "algo_mf = MatrixFactorization()\n",
    "\n",
    "# Reduce the candidates space + build user-user cosin similarity matrix \n",
    "algo_mf.fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decimal-fields",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 694 ms, sys: 7.54 ms, total: 702 ms\n",
      "Wall time: 705 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Ask for rating predictions for u users\n",
    "for u in range (1,10):\n",
    "    recs = algo_mf.recommend(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mysterious-permit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_ratings</th>\n",
       "      <th>normalized_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.998031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.996063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.938976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.887795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.846457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.824803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.811024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.773622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.765748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.753937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.742126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.720472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.716535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.687008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.687008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.659449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.649606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.639764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.635827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_ratings  normalized_popularity\n",
       "258                5.0               1.000000\n",
       "100                5.0               0.998031\n",
       "181                5.0               0.996063\n",
       "288                5.0               0.938976\n",
       "1                  5.0               0.887795\n",
       "300                5.0               0.846457\n",
       "174                5.0               0.824803\n",
       "127                5.0               0.811024\n",
       "56                 5.0               0.773622\n",
       "98                 5.0               0.765748\n",
       "237                5.0               0.753937\n",
       "117                5.0               0.742126\n",
       "172                5.0               0.720472\n",
       "222                5.0               0.716535\n",
       "204                5.0               0.687008\n",
       "313                5.0               0.687008\n",
       "79                 5.0               0.659449\n",
       "210                5.0               0.649606\n",
       "151                5.0               0.639764\n",
       "173                5.0               0.635827"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the last set of recommendations\n",
    "recs.sort_values(\n",
    "    by=[\"predicted_ratings\", \"normalized_popularity\"],\n",
    "    ascending=False\n",
    ")[[\"predicted_ratings\", \"normalized_popularity\"]].head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
