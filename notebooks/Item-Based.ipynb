{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sporting-triangle",
   "metadata": {},
   "source": [
    "# Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exciting-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, Predictor, als, basic, user_knn\n",
    "from lenskit import topn\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lenskit.data import sparse_ratings\n",
    "\n",
    "# Dataset\n",
    "from lenskit.datasets import ML100K\n",
    "movielens = ML100K('../ml-100k')\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Visualizations and debugging\n",
    "import plotly.graph_objs as go\n",
    "#from pprintpp import pprint as pp\n",
    "import logging\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "basic-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.datasets import ML100K\n",
    "movielens = ML100K('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "scheduled-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offensive-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "ratings = movielens.ratings\n",
    "uir, users, items = sparse_ratings(ratings, scipy=True)\n",
    "M = uir\n",
    "lambda1,lambda2,tol = 1.0,10.0,1e-3\n",
    "X_o=csr_matrix(M.shape)\n",
    "Z=csr_matrix(M.shape)\n",
    "Gamma=csr_matrix(M.shape)\n",
    "M_s = (uir!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recorded-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemBasedCosinSimilarity(Recommender, Predictor):\n",
    "    \"\"\"\n",
    "    Recommend new items by finding items that are the most similar to already rated items by users using the cosin distance formula\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_neighbors = 11, min_neighbors=1, min_sim=0, alpha=0.5, explore_percent=0.3, selector = None):\n",
    "        \n",
    "        # Set selector\n",
    "        if selector is None:\n",
    "            self.selector = basic.UnratedItemCandidateSelector()\n",
    "        else:\n",
    "            self.selector = selector\n",
    "            \n",
    "        # Set parameters\n",
    "        self.min_neighbors = min_neighbors\n",
    "        self.min_sim = min_sim\n",
    "        self.n_neighbors = n_neighbors\n",
    "        \n",
    "        # Determines the weight given to normalized popularity\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.explore_percent = explore_percent\n",
    "        \n",
    "        # Enable logging \n",
    "        _logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'ItemBasedCosinSimilarity'\n",
    "            \n",
    "    # Store the ratings matrix in sparse format and generate similarity matrix\n",
    "    def fit(self, ratings, **kwargs):\n",
    "        \n",
    "        # Get sparse representation in CSR format\n",
    "        uir, users, items = sparse_ratings(ratings, scipy=True)\n",
    "        \n",
    "        # Store ratings\n",
    "        self.rating_matrix_ = uir\n",
    "        self.user_index_ = users\n",
    "        self.item_index_ = items\n",
    "        self.rating_matrix_iur = uir.T\n",
    "        \n",
    "        knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "        knn.fit(self.rating_matrix_iur)\n",
    "        distances, indices = knn.kneighbors(self.rating_matrix_iur, n_neighbors=self.n_neighbors)\n",
    "        \n",
    "        self.distances = distances\n",
    "        self.indices = indices\n",
    "        \n",
    "        # Reduce candidate space to unseen items\n",
    "        self.selector.fit(ratings)\n",
    "    \n",
    "    # Add a user to the ratings matrix\n",
    "    def add_user(self, user_id):\n",
    "        \n",
    "        # Check if user_id to be added already exists\n",
    "        try:\n",
    "            assert (user_id in self.user_index_) == False, \"User ID already exists! Not adding anything...\"\n",
    "        \n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "            exit(1)\n",
    "\n",
    "        # Build a sparse matrix of length of number of items\n",
    "        tmp_sparse_row = sparse.csr_matrix(np.zeros((1,len(self.item_index_))))\n",
    "\n",
    "        # Vertically stack temporary matrix to original matrix\n",
    "        self.rating_matrix_ = sparse.vstack([self.rating_matrix_, tmp_sparse_row])\n",
    "        \n",
    "        # Update user index\n",
    "        self.user_index_ = self.user_index_.append(pd.Index([user_id]))\n",
    "    \n",
    "        \n",
    "    # Add a item to the ratings matrix\n",
    "    def add_item(self, item_id):\n",
    "        \n",
    "        # Check if item_id to be added already exists\n",
    "        try:\n",
    "            assert (item_id in self.item_index_) == False, \"Item ID already exists!\"\n",
    "        \n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "            exit(1)\n",
    "        \n",
    "        # Build a sparse matrix of length of number of users\n",
    "        tmp_sparse_col = sparse.csr_matrix(np.zeros((len(self.user_index_),1)))\n",
    "        \n",
    "        # Horizotnally stack temporary matrix to original matrix\n",
    "        self.rating_matrix_ = sparse.hstack([self.rating_matrix_, tmp_sparse_col])\n",
    "        \n",
    "        # Update item index\n",
    "        self.item_index_ = self.item_index_.append(pd.Index([item_id]))\n",
    "        \n",
    "        \n",
    "    # Add a user-item interaction for existing users and items\n",
    "    def add_interactions(self, user_id, item_id, rating):\n",
    "    \n",
    "        # Check if inputs are lists and all input list lengths are equal\n",
    "        assert type(user_id) == list, \"Input user_id is not a list\"\n",
    "        assert type(item_id) == list , \"Input item_id is not a list\"\n",
    "        assert type(rating) == list, \"Input rating is not a list\"\n",
    "        assert len(user_id) == len(item_id) == len(rating), \"Input lists are not of the same length\"\n",
    "        \n",
    "        # Build a temporary sparse LIL matrix\n",
    "        \n",
    "        tmp_ratings = sparse.lil_matrix(self.rating_matrix_.shape)\n",
    "        \n",
    "        for i in range(len(user_id)):\n",
    "            \n",
    "            # Obtain locations from ID\n",
    "            user_pos, = np.where(self.user_index_ == user_id[i])[0]\n",
    "            item_pos, = np.where(self.item_index_ == item_id[i])[0]\n",
    "            \n",
    "            # Fill into temporary sparse matrix\n",
    "            tmp_ratings[user_pos, item_pos] = rating[i]\n",
    "                    \n",
    "        # Convert temporary LIL to CSR\n",
    "        tmp_ratings = tmp_ratings.tocsr()\n",
    "        \n",
    "        # Add temporary CSR to main ratings matrix\n",
    "        self.rating_matrix_ += tmp_ratings\n",
    "\n",
    "    # Provide a recommendation of top \"n\" movies given \"user\"\n",
    "    # The recommender uses the UnratedItemCandidateSelector by default and uses the ratings matrix \n",
    "    # it was originally fit on\n",
    "    def recommend(self, user_id, candidates=None, ratings=None):\n",
    "        \n",
    "        # Reduce candidate space and store candidates with item ID\n",
    "        if candidates is None:\n",
    "            candidates = self.selector.candidates(user_id, ratings)\n",
    "        \n",
    "        # Grab user index for given user_id\n",
    "        user_index, = np.where(self.user_index_ == user_id)[0]\n",
    "        \n",
    "        # Predict ratings and scores for all unseen items\n",
    "        prediction_score_df = self.predict_for_user(user_index, candidates)\n",
    "        \n",
    "        return(prediction_score_df) \n",
    "    \n",
    "    # Modified from https://towardsdatascience.com/item-based-collaborative-filtering-in-python-91f747200fab\n",
    "    def predict_for_user(self, user, items):\n",
    "        \n",
    "        # Instantiate ratings and item_popularity vectors\n",
    "        predicted_ratings = np.zeros(len(items), dtype=float)\n",
    "        item_popularity = np.zeros(len(items), dtype=float)\n",
    "        \n",
    "        coo_ratings = self.rating_matrix_.tocoo()\n",
    "        rating_matrix_users = coo_ratings.row\n",
    "        rating_matrix_items = coo_ratings.col\n",
    "        rating_matrix_data = coo_ratings.data\n",
    "        \n",
    "        iur = self.rating_matrix_iur\n",
    "        iur_copy = iur.copy()\n",
    "        for i in range(len(items)):\n",
    "\n",
    "            m = self.item_index_.get_loc(items[i])\n",
    "            sim_movies = self.indices[m].tolist()\n",
    "            movie_distances = self.distances[m].tolist()\n",
    "\n",
    "            # Generally, this is the case: indices[3] = [3 6 7]. The movie itself is in the first place.\n",
    "            # In this case, we take off 3 from the list. Then, indices[3] == [6 7] to have the nearest NEIGHBORS in the list. \n",
    "            if m in sim_movies:\n",
    "              id_movie = sim_movies.index(m)\n",
    "              sim_movies.remove(m)\n",
    "              movie_distances.pop(id_movie) \n",
    "\n",
    "            # However, if the percentage of ratings in the dataset is very low, there are too many 0s in the dataset. \n",
    "            # Some movies have all 0 ratings and the movies with all 0s are considered the same movies by NearestNeighbors(). \n",
    "            # Then,even the movie itself cannot be included in the indices. \n",
    "            # For example, indices[3] = [2 4 7] is possible if movie_2, movie_3, movie_4, and movie_7 have all 0s for their ratings.\n",
    "            # In that case, we take off the farthest movie in the list. Therefore, 7 is taken off from the list, then indices[3] == [2 4].\n",
    "            else:\n",
    "              sim_movies = sim_movies[:self.n_neighbors-1]\n",
    "              movie_distances = movie_distances[:self.n_neighbors-1]\n",
    "\n",
    "            # movie_similarty = 1 - movie_distance    \n",
    "            movie_similarity = [1-x for x in movie_distances]\n",
    "            movie_similarity_copy = movie_similarity.copy()\n",
    "            nominator = 0\n",
    "\n",
    "            # for each similar movie\n",
    "            for s in range(0, len(movie_similarity)):\n",
    "\n",
    "              # check if the rating of a similar movie is zero\n",
    "              if iur[sim_movies[s], user] == 0:\n",
    "\n",
    "                # if the rating is zero, ignore the rating and the similarity in calculating the predicted rating\n",
    "                if len(movie_similarity_copy) == (self.n_neighbors - 1):\n",
    "                  movie_similarity_copy.pop(s)\n",
    "\n",
    "                else:\n",
    "                  movie_similarity_copy.pop(s-(len(movie_similarity)-len(movie_similarity_copy)))\n",
    "\n",
    "              # if the rating is not zero, use the rating and similarity in the calculation\n",
    "              else:\n",
    "                nominator = nominator + movie_similarity[s]*iur[sim_movies[s],user]\n",
    "\n",
    "            # check if the number of the ratings with non-zero is positive\n",
    "            if len(movie_similarity_copy) > 0:\n",
    "\n",
    "              # check if the sum of the ratings of the similar movies is positive.\n",
    "              if sum(movie_similarity_copy) > 0:\n",
    "                predicted_r = nominator/sum(movie_similarity_copy)\n",
    "\n",
    "              # Even if there are some movies for which the ratings are positive, some movies have zero similarity even though they are selected as similar movies.\n",
    "              # in this case, the predicted rating becomes zero as well  \n",
    "              else:\n",
    "                predicted_r = 0\n",
    "\n",
    "            # if all the ratings of the similar movies are zero, then predicted rating should be zero\n",
    "            else:\n",
    "              predicted_r = 0\n",
    "\n",
    "          # place the predicted rating into the copy of the original dataset\n",
    "#            iur_copy[m,user_index] = predicted_r\n",
    "            predicted_ratings[i] = predicted_r\n",
    "            \n",
    "            # Item position given item i ID\n",
    "            item_pos = self.item_index_.get_loc(items[i])\n",
    "            \n",
    "            # Locations of ratings for item_pos\n",
    "            rating_locations, = np.where(rating_matrix_items == item_pos)\n",
    "            \n",
    "            # Store popularity of item based on number of total ratings \n",
    "            item_popularity[i] = len(rating_locations)\n",
    "        \n",
    "        # minmax scale the popularity of each item\n",
    "        normalized_popularity = np.interp(item_popularity, (item_popularity.min(), item_popularity.max()), (0, +1))\n",
    "        score = np.multiply(normalized_popularity, predicted_ratings)\n",
    "        \n",
    "        results = {'predicted_ratings':predicted_ratings, 'normalized_popularity':normalized_popularity}\n",
    "        return pd.DataFrame(results, index=items)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forced-format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 478 ms, sys: 31.5 ms, total: 510 ms\n",
      "Wall time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Instantiate object\n",
    "algo_mf = ItemBasedCosinSimilarity()\n",
    "\n",
    "# Reduce the candidates space + build user-user cosin similarity matrix \n",
    "algo_mf.fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thirty-crest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.85 s, sys: 22.3 ms, total: 3.87 s\n",
      "Wall time: 3.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Ask for rating predictions for u users\n",
    "for u in range (1,10):\n",
    "    recs = algo_mf.recommend(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smoking-arlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_ratings</th>\n",
       "      <th>normalized_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.393701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.336614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.253937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.236220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.096457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.043307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.996063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.887795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.842520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.824803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.811024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.765748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.753937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.720472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.675197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.649606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.635827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.594488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.578740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.574803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted_ratings  normalized_popularity\n",
       "515                 5.0               0.393701\n",
       "255                 5.0               0.336614\n",
       "249                 5.0               0.253937\n",
       "510                 5.0               0.236220\n",
       "490                 5.0               0.096457\n",
       "1258                5.0               0.043307\n",
       "181                 5.0               0.996063\n",
       "1                   5.0               0.887795\n",
       "121                 5.0               0.842520\n",
       "174                 5.0               0.824803\n",
       "127                 5.0               0.811024\n",
       "98                  5.0               0.765748\n",
       "237                 5.0               0.753937\n",
       "172                 5.0               0.720472\n",
       "405                 5.0               0.675197\n",
       "210                 5.0               0.649606\n",
       "173                 5.0               0.635827\n",
       "257                 5.0               0.594488\n",
       "96                  5.0               0.578740\n",
       "118                 5.0               0.574803"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the last set of recommendations\n",
    "recs.sort_values(\n",
    "    by=[\"predicted_ratings\", \"normalized_popularity\"],\n",
    "    ascending=False\n",
    ")[[\"predicted_ratings\", \"normalized_popularity\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-peace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
